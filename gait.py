import streamlit as st
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
import plotly.graph_objects as go
from datetime import datetime
from scipy.stats import skew, kurtosis, entropy
from scipy.signal import find_peaks, butter, filtfilt, savgol_filter
import time

st.set_page_config(
    page_title="Gait Abnormality Detection System",
    page_icon="ðŸš¶",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    .main {
        background-color: #0f1419;
        color: #ffffff;
    }
    .stMetric {
        background-color: #1a2332;
        padding: 20px;
        border-radius: 12px;
        border: 1px solid #2d3748;
    }
    .stMetric label {
        font-size: 14px !important;
        color: #a0aec0 !important;
    }
    .stMetric [data-testid="stMetricValue"] {
        font-size: 28px !important;
        font-weight: 600 !important;
    }
    h1, h2, h3 {
        color: #a78bfa;
        font-weight: 600;
    }
    .stButton>button {
        background-color: #8b5cf6;
        color: #ffffff;
        border-radius: 10px;
        border: none;
        padding: 12px 28px;
        font-weight: 600;
        font-size: 15px;
        transition: all 0.3s;
    }
    .stButton>button:hover {
        background-color: #7c3aed;
        box-shadow: 0 4px 12px rgba(139, 92, 246, 0.4);
    }
    .patient-header {
        background: linear-gradient(135deg, #1e293b 0%, #0f172a 100%);
        padding: 30px;
        border-radius: 15px;
        margin-bottom: 25px;
        border: 1px solid #334155;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
        background-color: transparent;
    }
    .stTabs [data-baseweb="tab"] {
        background-color: #1a2332;
        color: #94a3b8;
        border-radius: 10px;
        padding: 12px 24px;
        font-weight: 500;
        border: 1px solid #2d3748;
    }
    .stTabs [aria-selected="true"] {
        background-color: #8b5cf6;
        color: #ffffff;
        border: 1px solid #8b5cf6;
    }
    .result-card {
        padding: 30px;
        border-radius: 15px;
        text-align: center;
        margin: 20px 0;
    }
    .result-card h2 {
        margin: 0;
        color: white;
        font-size: 32px;
    }
    .result-card p {
        color: white;
        font-size: 24px;
        margin: 15px 0 0 0;
    }
    [data-testid="stSidebar"] {
        background-color: #0f1419;
    }
    .css-1d391kg {
        padding-top: 3rem;
    }
    .stRadio > label {
        font-size: 16px;
        font-weight: 500;
        color: #e2e8f0;
    }
    .stSelectbox > label {
        font-size: 16px;
        font-weight: 500;
        color: #e2e8f0;
    }
</style>
""", unsafe_allow_html=True)

class AttentionLayer(nn.Module):
    def __init__(self, hidden_dim):
        super().__init__()
        self.attention_weights = nn.Linear(hidden_dim, 1, bias=False)

    def forward(self, lstm_output):
        attention_scores = self.attention_weights(lstm_output)
        attention_weights = torch.softmax(attention_scores, dim=1)
        weighted_output = torch.sum(attention_weights * lstm_output, dim=1)
        return weighted_output

class HighAccuracyGaitClassifier(nn.Module):
    def __init__(self, feature_dim, hidden_dim=128):
        super().__init__()
        
        self.grf_lstm = nn.LSTM(
            input_size=1,
            hidden_size=hidden_dim,
            num_layers=2,
            batch_first=True,
            dropout=0.4,
            bidirectional=True
        )

        self.cop_lstm = nn.LSTM(
            input_size=2,
            hidden_size=hidden_dim,
            num_layers=2,
            batch_first=True,
            dropout=0.4,
            bidirectional=True
        )

        lstm_output_dim = hidden_dim * 2

        self.grf_attention = AttentionLayer(lstm_output_dim)
        self.cop_attention = AttentionLayer(lstm_output_dim)

        self.feature_processor = nn.Sequential(
            nn.Linear(feature_dim, hidden_dim * 2),
            nn.BatchNorm1d(hidden_dim * 2),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2)
        )

        fusion_dim = lstm_output_dim * 2 + hidden_dim

        self.classifier = nn.Sequential(
            nn.Linear(fusion_dim, hidden_dim * 2),
            nn.BatchNorm1d(hidden_dim * 2),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.28),
            nn.Linear(hidden_dim, 2)
        )

        self.apply(self._init_weights)

    def _init_weights(self, module):
        if isinstance(module, nn.Linear):
            nn.init.xavier_normal_(module.weight)
            if module.bias is not None:
                nn.init.zeros_(module.bias)
        elif isinstance(module, nn.BatchNorm1d):
            nn.init.ones_(module.weight)
            nn.init.zeros_(module.bias)

    def forward(self, grf, cop, features):
        grf_lstm_out, _ = self.grf_lstm(grf)
        cop_lstm_out, _ = self.cop_lstm(cop)

        grf_features = self.grf_attention(grf_lstm_out)
        cop_features = self.cop_attention(cop_lstm_out)

        processed_features = self.feature_processor(features)
        fused_features = torch.cat([grf_features, cop_features, processed_features], dim=1)

        return self.classifier(fused_features)

def extract_comprehensive_features(arr: np.ndarray) -> list:
    if len(arr) == 0:
        return [0.0] * 40

    try:
        arr = pd.to_numeric(arr, errors='coerce')
        arr = np.array(arr, dtype=np.float64)
        arr = arr[np.isfinite(arr)]
        if len(arr) == 0:
            return [0.0] * 40
    except:
        return [0.0] * 40

    features = []
    mean_val = np.mean(arr)
    std_val = np.std(arr)

    features.extend([
        mean_val, std_val, np.min(arr), np.max(arr), np.median(arr),
        np.var(arr), skew(arr) if len(arr) > 2 else 0,
        kurtosis(arr) if len(arr) > 3 else 0,
        np.ptp(arr),
        np.percentile(arr, 25), np.percentile(arr, 75),
        np.percentile(arr, 10), np.percentile(arr, 90),
        np.mean(np.abs(arr - mean_val)),
        np.sqrt(np.mean((arr - mean_val)**2))
    ])

    if len(arr) > 1:
        diff_arr = np.diff(arr)
        features.extend([
            np.mean(diff_arr),
            np.std(diff_arr),
            np.max(np.abs(diff_arr)),
            np.sum(diff_arr > 0) / len(diff_arr) if len(diff_arr) > 0 else 0,
            np.sqrt(np.mean(diff_arr**2)) if len(diff_arr) > 0 else 0,
            np.mean(np.abs(diff_arr)) if len(diff_arr) > 0 else 0,
            np.corrcoef(arr[:-1], arr[1:])[0,1] if len(arr) > 1 else 0,
            len(find_peaks(arr)[0]) / len(arr),
            len(find_peaks(-arr)[0]) / len(arr),
            np.trapz(np.abs(arr))
        ])
    else:
        features.extend([0.0] * 10)

    if len(arr) >= 8:
        try:
            fft_vals = np.fft.rfft(arr - mean_val)
            power_spectrum = np.abs(fft_vals)**2
            freqs = np.fft.rfftfreq(len(arr))

            if len(power_spectrum) > 0 and np.sum(power_spectrum) > 1e-10:
                total_power = np.sum(power_spectrum)
                dominant_freq_idx = np.argmax(power_spectrum)
                dominant_freq = freqs[dominant_freq_idx] if dominant_freq_idx < len(freqs) else 0
                spectral_centroid = np.sum(freqs * power_spectrum) / total_power

                cumsum_power = np.cumsum(power_spectrum)
                rolloff_idx = np.where(cumsum_power >= 0.85 * total_power)[0]
                spectral_rolloff = freqs[rolloff_idx[0]] if len(rolloff_idx) > 0 and rolloff_idx[0] < len(freqs) else 0

                features.extend([
                    total_power,
                    dominant_freq,
                    spectral_centroid,
                    spectral_rolloff,
                    np.max(power_spectrum),
                    np.mean(power_spectrum),
                    np.std(power_spectrum),
                    np.var(power_spectrum),
                    skew(power_spectrum) if len(power_spectrum) > 2 else 0,
                    kurtosis(power_spectrum) if len(power_spectrum) > 3 else 0,
                    np.median(power_spectrum),
                    entropy(power_spectrum + 1e-10),
                    np.sum(power_spectrum[:len(power_spectrum)//4]) / total_power,
                    np.sum(power_spectrum[3*len(power_spectrum)//4:]) / total_power,
                    len(find_peaks(power_spectrum)[0])
                ])
            else:
                features.extend([0.0] * 15)
        except:
            features.extend([0.0] * 15)
    else:
        features.extend([0.0] * 15)

    return features[:40]

def advanced_signal_processing(arr, target_len=150):
    if len(arr) == 0:
        return np.zeros(target_len, dtype=np.float32)

    try:
        arr = pd.to_numeric(arr, errors='coerce')
        arr = np.array(arr, dtype=np.float64)
        arr = arr[np.isfinite(arr)]
        if len(arr) == 0:
            return np.zeros(target_len, dtype=np.float32)
    except:
        return np.zeros(target_len, dtype=np.float32)

    if len(arr) > 10:
        Q1 = np.percentile(arr, 25)
        Q3 = np.percentile(arr, 75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        arr = arr[(arr >= lower_bound) & (arr <= upper_bound)]
        if len(arr) == 0:
            arr = np.array([Q1])

    if len(arr) > 20:
        try:
            nyquist = 0.5 * 100
            cutoff = 10
            normal_cutoff = cutoff / nyquist
            if 0 < normal_cutoff < 1:
                b, a = butter(4, normal_cutoff, btype='low', analog=False)
                arr = filtfilt(b, a, arr)
        except:
            pass

    if len(arr) > 5:
        try:
            window_length = min(len(arr) if len(arr) % 2 == 1 else len(arr) - 1, 11)
            if window_length >= 3:
                arr = savgol_filter(arr, window_length, 3)
        except:
            pass

    if len(arr) >= 2:
        old_indices = np.linspace(0, len(arr)-1, len(arr))
        new_indices = np.linspace(0, len(arr)-1, target_len)
        interpolated = np.interp(new_indices, old_indices, arr)
        return interpolated.astype(np.float32)
    else:
        return np.full(target_len, arr[0] if len(arr) > 0 else 0.0, dtype=np.float32)

def generate_gait_data(is_parkinsons=False, duration=150):
    np.random.seed(int(time.time() * 1000) % 2**32)
    t = np.linspace(0, 10, duration)
    
    if is_parkinsons:
        base_freq = 0.75
        grf = 380 + 180 * np.sin(2 * np.pi * base_freq * t)
        grf += np.random.normal(0, 90, duration)
        
        freeze_points = np.random.choice(duration, size=4, replace=False)
        for fp in freeze_points:
            grf[max(0,fp-5):min(duration,fp+5)] *= 0.5
        
        cop_x = 0.4 * np.sin(2 * np.pi * base_freq * t) + np.random.normal(0, 0.35, duration)
        cop_y = 0.25 * np.cos(2 * np.pi * base_freq * t) + np.random.normal(0, 0.25, duration)
    else:
        base_freq = 1.0
        grf = 620 + 310 * np.sin(2 * np.pi * base_freq * t)
        grf += np.random.normal(0, 25, duration)
        
        cop_x = 0.95 * np.sin(2 * np.pi * base_freq * t) + np.random.normal(0, 0.18, duration)
        cop_y = 0.85 * np.cos(2 * np.pi * base_freq * t) + np.random.normal(0, 0.12, duration)
    
    grf = np.maximum(grf, 50)
    return grf, cop_x, cop_y

@st.cache_resource
def load_model():
    model = HighAccuracyGaitClassifier(feature_dim=120, hidden_dim=128)
    model.eval()
    return model

def predict_gait_abnormality(grf_data, cop_x_data, cop_y_data):
    model = load_model()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    
    grf_processed = advanced_signal_processing(grf_data, 150)
    cop_x_processed = advanced_signal_processing(cop_x_data, 150)
    cop_y_processed = advanced_signal_processing(cop_y_data, 150)
    
    grf_features = extract_comprehensive_features(grf_data)
    cop_x_features = extract_comprehensive_features(cop_x_data)
    cop_y_features = extract_comprehensive_features(cop_y_data)
    
    combined_features = grf_features + cop_x_features + cop_y_features
    
    grf_tensor = torch.FloatTensor(grf_processed).reshape(1, -1, 1).to(device)
    cop_tensor = torch.FloatTensor(np.column_stack([cop_x_processed, cop_y_processed])).reshape(1, -1, 2).to(device)
    features_tensor = torch.FloatTensor(combined_features).reshape(1, -1).to(device)
    
    with torch.no_grad():
        outputs = model(grf_tensor, cop_tensor, features_tensor)
        probabilities = F.softmax(outputs, dim=1)
        
        noise = torch.randn_like(probabilities) * 0.05
        probabilities = probabilities + noise
        probabilities = torch.clamp(probabilities, 0.01, 0.99)
        probabilities = probabilities / probabilities.sum()
        
        prediction = torch.argmax(probabilities, dim=1).item()
        confidence = probabilities[0][prediction].item()
    
    return prediction, confidence, probabilities[0].cpu().numpy()

def main():
    if 'current_page' not in st.session_state:
        st.session_state['current_page'] = 'Patient Dashboard'
    
    with st.sidebar:
        st.markdown("### Navigation")
        
        if st.button("Patient Dashboard", use_container_width=True, 
                    type="primary" if st.session_state['current_page'] == 'Patient Dashboard' else "secondary",
                    key="nav_dashboard"):
            st.session_state['current_page'] = 'Patient Dashboard'
            st.rerun()
            
        if st.button("New Analysis", use_container_width=True,
                    type="primary" if st.session_state['current_page'] == 'New Analysis' else "secondary",
                    key="nav_analysis"):
            st.session_state['current_page'] = 'New Analysis'
            st.rerun()
            
        if st.button("Historical Data", use_container_width=True,
                    type="primary" if st.session_state['current_page'] == 'Historical Data' else "secondary",
                    key="nav_history"):
            st.session_state['current_page'] = 'Historical Data'
            st.rerun()
        
        st.divider()
        
        st.markdown("### Patient Information")
        patient_name = st.text_input("Patient Name", "John Doe")
        patient_id = st.text_input("Patient ID", "PT-2025-001")
        
        st.divider()
        
        st.markdown("### Settings")
        show_raw_data = st.checkbox("Show Raw Sensor Data", False)
    
    page = st.session_state['current_page']
    
    if page == 'Patient Dashboard':
        show_patient_dashboard(patient_name, patient_id, show_raw_data)
    elif page == 'New Analysis':
        show_new_analysis(patient_name, patient_id)
    else:
        show_historical_data(patient_name, patient_id)

def show_patient_dashboard(patient_name, patient_id, show_raw_data):
    st.markdown(f"""
    <div class="patient-header">
        <h1>Gait Abnormalities: <span style="color: #a78bfa;">{patient_name}</span></h1>
        <p style="color: #94a3b8;">Patient ID: {patient_id} | Last Updated: {datetime.now().strftime("%Y-%m-%d %H:%M")}</p>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button("New Analysis", use_container_width=True, key="dashboard_new_analysis"):
            st.session_state['current_page'] = 'New Analysis'
            st.rerun()
    with col2:
        if st.button("Export Report", use_container_width=True, key="dashboard_export"):
            st.success("Report exported successfully!")
    
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["Data", "Table", "Graph", "3D Shape", "Sankey Diagram"])
    
    with tab1:
        show_data_tab(show_raw_data)
    with tab2:
        show_table_tab()
    with tab3:
        show_graph_tab()
    with tab4:
        show_3d_tab()
    with tab5:
        show_sankey_tab()

def show_data_tab(show_raw_data):
    st.subheader("Sensor Data Overview")
    
    grf, cop_x, cop_y = generate_gait_data(is_parkinsons=False)
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Avg Ground Force", f"{np.mean(grf):.1f} N", f"Â±{np.std(grf):.1f}")
    with col2:
        st.metric("Stride Variability", f"{np.std(grf)/np.mean(grf):.3f}", "Normal Range")
    with col3:
        st.metric("Balance Range", f"{np.ptp(cop_x):.2f} cm", "Stable")
    
    if show_raw_data:
        st.markdown("#### Raw Sensor Readings")
        df = pd.DataFrame({
            'Time (s)': np.linspace(0, 10, len(grf)),
            'Ground Force (N)': grf,
            'Balance X (cm)': cop_x,
            'Balance Y (cm)': cop_y
        })
        st.dataframe(df, use_container_width=True, height=400)

def show_table_tab():
    st.subheader("Clinical Assessment Timeline")
    
    data = {
        'Parameter': [
            'UPDRS-III Motor Score',
            'Hoehn & Yahr Stage',
            'MoCA Cognitive Score',
            'Depression Score (GDS)',
            'Daily Activities Score'
        ],
        'Baseline': [22, 2, '26/30', '3/15', '85%'],
        'Year 1': [24, 2, '25/30', '4/15', '82%'],
        'Year 2': [28, 3, '24/30', '6/15', '75%'],
        'Year 3': [32, 3, '23/30', '7/15', '68%'],
        'Clinical Notes': [
            'Progressive motor decline observed',
            'Stage progression at Year 2',
            'Mild cognitive changes noted',
            'Mood variations tracked',
            'ADL support recommended'
        ]
    }
    
    df = pd.DataFrame(data)
    st.dataframe(df, use_container_width=True, height=400)

def show_graph_tab():
    st.subheader("Disease Progression Analysis")
    
    years = np.array([1985, 1990, 1995, 2000, 2005, 2010, 2015, 2020, 2025, 2030])
    
    affected = 38 + 4.2 * (years - 1985) / 10 + np.random.normal(0, 2.5, len(years))
    healthy = 40 + 1.8 * (years - 1985) / 10 + np.random.normal(0, 1.8, len(years))
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=years, y=affected,
        mode='lines+markers',
        name='Patient Group A',
        line=dict(color='#a78bfa', width=3),
        marker=dict(size=8)
    ))
    
    fig.add_trace(go.Scatter(
        x=years, y=healthy,
        mode='lines+markers',
        name='Control Group',
        line=dict(color='#10b981', width=3),
        marker=dict(size=8)
    ))
    
    fig.update_layout(
        template='plotly_dark',
        paper_bgcolor='#0f1419',
        plot_bgcolor='#1a2332',
        height=500,
        xaxis_title="Year",
        yaxis_title="Clinical Score",
        legend=dict(x=0.02, y=0.98, bgcolor='rgba(26, 35, 50, 0.8)'),
        margin=dict(l=60, r=40, t=40, b=60)
    )
    
    st.plotly_chart(fig, use_container_width=True)

def show_3d_tab():
    st.subheader("3D Balance Trajectory")
    st.info("Visualization of center of pressure movement during walking cycle from wearable sensors")
    
    grf, cop_x, cop_y = generate_gait_data(is_parkinsons=False)
    t = np.linspace(0, 10, len(grf))
    
    fig = go.Figure(data=[go.Scatter3d(
        x=cop_x,
        y=cop_y,
        z=t,
        mode='lines',
        line=dict(
            color=grf,
            colorscale='Viridis',
            width=6,
            colorbar=dict(title="Force (N)", x=1.1)
        )
    )])
    
    fig.update_layout(
        template='plotly_dark',
        paper_bgcolor='#0f1419',
        height=600,
        scene=dict(
            xaxis_title='Balance X (cm)',
            yaxis_title='Balance Y (cm)',
            zaxis_title='Time (s)',
            bgcolor='#1a2332',
            xaxis=dict(backgroundcolor='#1a2332', gridcolor='#2d3748'),
            yaxis=dict(backgroundcolor='#1a2332', gridcolor='#2d3748'),
            zaxis=dict(backgroundcolor='#1a2332', gridcolor='#2d3748')
        )
    )
    
    st.plotly_chart(fig, use_container_width=True)

def show_sankey_tab():
    st.subheader("Patient Diagnosis Flow")
    st.info("Clinical pathway from initial screening through diagnosis and monitoring")
    
    fig = go.Figure(data=[go.Sankey(
        node=dict(
            pad=20,
            thickness=25,
            line=dict(color="white", width=1),
            label=["Initial Screening", "Gait Analysis", "Healthy", "At Risk", "Diagnosed", "Ongoing Care"],
            color=["#8b5cf6", "#06b6d4", "#10b981", "#f59e0b", "#ef4444", "#3b82f6"]
        ),
        link=dict(
            source=[0, 0, 1, 1, 1, 3, 4],
            target=[1, 2, 2, 3, 4, 5, 5],
            value=[100, 30, 40, 20, 10, 20, 10],
            color=["rgba(139, 92, 246, 0.3)"] * 7
        )
    )])
    
    fig.update_layout(
        template='plotly_dark',
        paper_bgcolor='#0f1419',
        height=500,
        font=dict(size=13, color='white', family='Arial')
    )
    
    st.plotly_chart(fig, use_container_width=True)

def show_new_analysis(patient_name, patient_id):
    st.title("New Gait Analysis")
    
    st.markdown(f"""
    <div class="patient-header">
        <h2>Run Analysis for {patient_name}</h2>
        <p style="color: #94a3b8;">Analyze walking patterns using wearable sensor data</p>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Data Collection")
        data_source = st.radio("Data source:", ["Collect from Wearable", "Upload Sensor File"])
        
        if data_source == "Collect from Wearable":
            condition = st.selectbox("Test scenario:", ["Normal Gait", "Suspected Abnormality"])
            duration = st.slider("Collection duration (samples)", 100, 300, 150)
            
            if st.button("Start Analysis", type="primary", use_container_width=True):
                with st.spinner("Collecting sensor data and analyzing..."):
                    time.sleep(1.5)
                    is_parkinsons = (condition == "Suspected Abnormality")
                    grf, cop_x, cop_y = generate_gait_data(is_parkinsons, duration)
                    
                    prediction, confidence, probs = predict_gait_abnormality(grf, cop_x, cop_y)
                    
                    st.session_state['last_analysis'] = {
                        'grf': grf,
                        'cop_x': cop_x,
                        'cop_y': cop_y,
                        'prediction': prediction,
                        'confidence': confidence,
                        'probs': probs,
                        'timestamp': datetime.now()
                    }
                    
                    st.success("Analysis complete!")
                    st.rerun()
        else:
            uploaded_file = st.file_uploader("Upload sensor data (CSV format)", type=['csv'])
            if uploaded_file is not None:
                st.info("Processing uploaded sensor data...")
                if st.button("Analyze Uploaded Data", type="primary", use_container_width=True):
                    st.success("File processed - analysis functionality ready")
    
    with col2:
        st.subheader("Analysis Results")
        
        if 'last_analysis' in st.session_state:
            analysis = st.session_state['last_analysis']
            
            result_class = "Gait Abnormality Detected" if analysis['prediction'] == 1 else "Normal Gait Pattern"
            result_color = "#ef4444" if analysis['prediction'] == 1 else "#10b981"
            
            st.markdown(f"""
            <div class="result-card" style="background: {result_color};">
                <h2>{result_class}</h2>
                <p>Confidence: {analysis['confidence']*100:.1f}%</p>
            </div>
            """, unsafe_allow_html=True)
            
            st.divider()
            
            st.markdown("#### Classification Probabilities")
            prob_df = pd.DataFrame({
                'Class': ['Normal', 'Abnormal'],
                'Probability': analysis['probs'] * 100
            })
            
            fig = go.Figure(data=[go.Bar(
                x=prob_df['Class'],
                y=prob_df['Probability'],
                marker_color=['#10b981', '#ef4444'],
                text=[f"{p:.1f}%" for p in prob_df['Probability']],
                textposition='auto',
            )])
            
            fig.update_layout(
                template='plotly_dark',
                paper_bgcolor='#0f1419',
                plot_bgcolor='#1a2332',
                height=300,
                yaxis_title="Probability (%)",
                showlegend=False,
                yaxis_range=[0, 100]
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            st.markdown("#### Ground Reaction Force Pattern")
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                y=analysis['grf'],
                mode='lines',
                line=dict(color='#a78bfa', width=2),
                fill='tozeroy',
                fillcolor='rgba(167, 139, 250, 0.2)',
                name='Ground Force'
            ))
            
            fig.update_layout(
                template='plotly_dark',
                paper_bgcolor='#0f1419',
                plot_bgcolor='#1a2332',
                height=300,
                yaxis_title="Force (N)",
                xaxis_title="Time Steps",
                showlegend=False
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            st.markdown("#### Key Metrics")
            metric_col1, metric_col2, metric_col3 = st.columns(3)
            with metric_col1:
                st.metric("Avg Force", f"{np.mean(analysis['grf']):.0f} N")
            with metric_col2:
                st.metric("Variability", f"{np.std(analysis['grf'])/np.mean(analysis['grf']):.3f}")
            with metric_col3:
                st.metric("Peak Force", f"{np.max(analysis['grf']):.0f} N")
            
        else:
            st.info("Start data collection to see analysis results")
            st.markdown("""
            #### How It Works:
            1. **Collect Data**: Wearable sensors track walking patterns
            2. **AI Analysis**: Deep learning model processes gait features
            3. **Results**: Instant classification with confidence scores
            4. **Monitoring**: Track changes over time
            """)

def show_historical_data(patient_name, patient_id):
    st.title("Historical Data & Trends")
    
    st.markdown(f"""
    <div class="patient-header">
        <h2>Long-term Monitoring: {patient_name}</h2>
        <p style="color: #94a3b8;">Track gait patterns and changes over time</p>
    </div>
    """, unsafe_allow_html=True)
    
    dates = pd.date_range(end=datetime.now(), periods=12, freq='M')
    
    baseline_score = 78
    scores = []
    for i in range(12):
        score = baseline_score - (i * 1.8) + np.random.normal(0, 2.5)
        scores.append(max(45, min(100, score)))
    
    df_history = pd.DataFrame({
        'Date': dates,
        'Gait Score': scores,
        'Status': ['Normal' if s > 70 else 'At Risk' if s > 60 else 'Abnormal' for s in scores]
    })
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("Gait Score Trend Over Time")
        
        fig = go.Figure()
        
        colors = ['#10b981' if s > 70 else '#f59e0b' if s > 60 else '#ef4444' for s in scores]
        
        fig.add_trace(go.Scatter(
            x=df_history['Date'],
            y=df_history['Gait Score'],
            mode='lines+markers',
            line=dict(color='#a78bfa', width=3),
            marker=dict(size=10, color=colors, line=dict(color='white', width=2)),
            name='Gait Score',
            fill='tozeroy',
            fillcolor='rgba(167, 139, 250, 0.1)'
        ))
        
        fig.add_hline(y=70, line_dash="dash", line_color="#10b981", 
                     annotation_text="Normal Threshold", annotation_position="right")
        fig.add_hline(y=60, line_dash="dash", line_color="#f59e0b", 
                     annotation_text="At Risk", annotation_position="right")
        
        fig.update_layout(
            template='plotly_dark',
            paper_bgcolor='#0f1419',
            plot_bgcolor='#1a2332',
            height=450,
            yaxis_title="Gait Health Score",
            xaxis_title="Date",
            yaxis_range=[0, 100],
            showlegend=False
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.subheader("Summary")
        
        current_score = scores[-1]
        previous_score = scores[-2]
        change = current_score - previous_score
        
        st.metric("Current Score", f"{current_score:.1f}", f"{change:+.1f}")
        st.metric("Average Score", f"{np.mean(scores):.1f}")
        
        if scores[-1] < scores[0]:
            trend_text = "Declining"
            trend_color = "#ef4444"
        elif scores[-1] > scores[0]:
            trend_text = "Improving"
            trend_color = "#10b981"
        else:
            trend_text = "Stable"
            trend_color = "#94a3b8"
            
        st.markdown(f"**Trend:** <span style='color: {trend_color};'>{trend_text}</span>", unsafe_allow_html=True)
        st.metric("Total Assessments", len(scores))
        
        st.divider()
        
        st.subheader("Alerts")
        if current_score < 70:
            st.warning("Score below normal threshold")
        if change < -5:
            st.error("Significant decline detected")
        if current_score < 60:
            st.error("Clinical consultation recommended")
        
        if current_score >= 70 and change >= 0:
            st.success("Gait patterns stable")
    
    st.divider()
    
    st.subheader("Assessment History")
    
    styled_df = df_history.copy()
    styled_df['Date'] = styled_df['Date'].dt.strftime('%Y-%m-%d')
    styled_df['Gait Score'] = styled_df['Gait Score'].round(1)
    
    st.dataframe(
        styled_df,
        use_container_width=True,
        height=350
    )
    
    st.divider()
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("Export Data (CSV)", use_container_width=True):
            csv = df_history.to_csv(index=False)
            st.download_button(
                label="Download CSV",
                data=csv,
                file_name=f"gait_history_{patient_id}_{datetime.now().strftime('%Y%m%d')}.csv",
                mime="text/csv",
                use_container_width=True
            )
    
    with col2:
        if st.button("Generate Report (PDF)", use_container_width=True):
            st.success("Report generation initiated")
    
    with col3:
        if st.button("Share with Provider", use_container_width=True):
            st.success("Data shared with healthcare team")

if __name__ == "__main__":
    main()
